{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for easy experimenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pradip.gupta/personal-projects/grab/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pradip.gupta/personal-projects/grab'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement for the Competition:\n",
    "\n",
    "As presented here: https://www.aiforsea.com/computer-vision\n",
    "\n",
    "### Given a dataset of distinct car images, can you automatically recognize the a) `car model` and b) `car make`?\n",
    "\n",
    "The problem statement talks about identifying car model and car make. So, there are 2 taget variables here. In the video presented [here](https://www.youtube.com/watch?v=7BL8EeAkNDw&feature=youtu.be&t=92) even `c) dominate color prediction` was posed as part of this problem, however, as that is not a part of the problem statement, I left that third component out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Car Make and Car Model?\n",
    "\n",
    "Lets understand what does these two terms mean: <br>\n",
    "\n",
    "A car's make is the brand of the vehicle, while the model refers to the name of a car product and sometimes a range of products. For example, Toyota is a car make and Camry is a car model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data:\n",
    "\n",
    "Source: https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n",
    "\n",
    "- The Cars dataset contains **16,185** images of **196 classes** of cars. \n",
    "\n",
    "- The data is split into **8,144 training** images and **8,041 testing** images, where each class has been split roughly in a 50-50 split. \n",
    "\n",
    "- Classes are typically at the level of Make, Model, Year, e.g. 2012 Tesla Model S or 2012 BMW M3 coupe.\n",
    "\n",
    "More about the dataset @: https://ai.stanford.edu/~jkrause/papers/3drr13.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Class Seperation:\n",
    "\n",
    "The intial thought was to treat the 2 target variables individually, and make a multi-task learning model, that can produce outputs for the 2 classes individually. However, as the hold-out data is not availabel, it was difficult to visualise what label structure the hold out data is following, so the idea of considering the output as two independent labels was **dropped**.\n",
    "\n",
    "However, I have presented the work here. Please note this seperation has **not** been used in the actually modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief study on different car models that exists:\n",
    "\n",
    "1. Hatchback, \n",
    "2. Sedan, \n",
    "3. MPV, \n",
    "4. SUV, \n",
    "5. Crossover, \n",
    "6. Coupe, \n",
    "7. Convertible, \n",
    "8. Truck, \n",
    "9. Van, \n",
    "10. Wagon,\n",
    "12. Sports car\n",
    "13. Diesel, \n",
    "14. Luxury car\n",
    "15. Electric\n",
    "\n",
    "others...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cars_meta.mat`: Contains a cell array of class names, one for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mat_io.loadmat(preprocessing[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i, label in enumerate(labels[\"class_names\"][0]):\n",
    "    \n",
    "    label = label[0]\n",
    "    make = label.split()[0]\n",
    "    descr = ' '.join(label.split()[1:-1])\n",
    "    model = label.split()[-2]\n",
    "    \n",
    "    if \"Martin\" in model:\n",
    "        make = \"Aston Martin\"\n",
    "        descr = descr.replace(\"Martin\",\"\")\n",
    "    \n",
    "    if make == \"AM\" and \"General\" in descr:\n",
    "        make = \"AM General\"\n",
    "        descr = descr.replace(\"General\", \"\")\n",
    "        \n",
    "    if descr == 'Integra Type R':\n",
    "         model = 'Type-R'\n",
    "\n",
    "    if model == 'Z06' or model == 'ZR1':\n",
    "        model = 'Convertible'\n",
    "\n",
    "    if 'SRT' in model:\n",
    "        model = 'SRT'\n",
    "\n",
    "    if model == 'IPL':\n",
    "        model = 'Coupe'\n",
    "\n",
    "    year = label.split()[-1]\n",
    "    data.append((i, label, make, descr, model, year))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['target', 'label', 'make', 'description', 'model', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.make.unique(), df.make.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.model.unique(), df.model.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = df[\"model\"]==\"SS\"\n",
    "desired_col = [\"label\"]\n",
    "df.loc[condition,desired_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With this exercise I could have defined 2 variables as make and model with 49 and 18 classes respectively. However, as the nature of Hold-out data was not known I skipped this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining ROI for Input images:\n",
    "\n",
    "To improve the classification accuracy, it is desired that we restric our AOI to the car region only and remove other background in the image which may act as noise and prevent the model from learning the right features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard imports\n",
    "from scipy import io as mat_io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 'data/devkit/cars_meta.mat',\n",
       " 'train_annotations': 'data/devkit/cars_train_annos.mat',\n",
       " 'test_annotations': 'data/devkit/cars_test_annos.mat',\n",
       " 'raw_train_images': 'data/raw/cars_train',\n",
       " 'raw_test_images': 'data/raw/cars_train',\n",
       " 'extracted_train_images': 'data/processed/cars_train'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Custom imports\n",
    "from src2.config import preprocessing\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = preprocessing[\"train_annotations\"]\n",
    "raw_train_images = preprocessing[\"raw_train_images\"]\n",
    "processed_train_images = preprocessing[\"extracted_train_images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mat_io.loadmat(preprocessing[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "class_names = []\n",
    "class_ids = []\n",
    "\n",
    "for i, label in enumerate(labels[\"class_names\"][0]):\n",
    "    class_dict[i] = label[0]\n",
    "    class_names.append(label[0])\n",
    "    class_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoations_dict = mat_io.loadmat(train_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As given at the datasource:\n",
    "\n",
    "`cars_train_annos.mat`: <br>\n",
    "\n",
    "Contains the variable 'annotations', which is a struct array of length num_images and where each element has the fields:\n",
    "\n",
    "- `bbox_x1:` Min x-value of the bounding box, in pixels\n",
    "- `bbox_x2:` Max x-value of the bounding box, in pixels\n",
    "- `bbox_y1:` Min y-value of the bounding box, in pixels\n",
    "- `bbox_y2:` Max y-value of the bounding box, in pixels\n",
    "- `class:` Integral id of the class the image belongs to.\n",
    "- `fname:` Filename of the image within the folder of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = []\n",
    "for annotation in annoations_dict['annotations'][0]:\n",
    "    \n",
    "    #path/to/image.jpg,x1,y1,x2,y2,class_name\n",
    "    \n",
    "    class_id = annotation[\"class\"][0][0] - 1\n",
    "    \n",
    "    value = (annotation[\"fname\"][0], annotation[\"bbox_x1\"][0][0], annotation[\"bbox_y1\"][0][0],\n",
    "            annotation[\"bbox_x2\"][0][0], annotation[\"bbox_y2\"][0][0], class_dict[class_id])\n",
    "    files_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_map_csv(class_names, class_ids):    \n",
    "    class_mapping = pd.DataFrame({\"class_names\":class_names,\n",
    "                     \"class_ids\":class_ids})\n",
    "    \n",
    "    return class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class']\n",
    "df = pd.DataFrame(files_list, columns=column_name) \n",
    "    \n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train_df = df[msk]\n",
    "val_df = df[~msk]\n",
    "    \n",
    "train_df.to_csv(raw_train_images+'/train_annotations.csv', header=False, index=None)\n",
    "val_df.to_csv(raw_train_images+'/val_annotations.csv', header=False, index=None)\n",
    "    \n",
    "class_mapping = class_map_csv(class_names, class_ids)\n",
    "class_mapping.to_csv(raw_train_images+\"/class_mapping.csv\",header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8144"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if all images were loaded properly\n",
    "assert df.shape[0] == 8144"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
